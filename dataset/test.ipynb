{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data conversion complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Define the path to the dataset\n",
    "data_path = \"DATASET\"\n",
    "\n",
    "# Load the train.csv file\n",
    "train_df = pd.read_csv(os.path.join(data_path, \"data.csv\"))\n",
    "\n",
    "# Create a new directory to store the YOLO format data\n",
    "yolo_data_path = os.path.join(data_path, \"yolo_data\")\n",
    "if not os.path.exists(yolo_data_path):\n",
    "    os.mkdir(yolo_data_path)\n",
    "    \n",
    "# Create a new directory to store the images\n",
    "yolo_images_path = os.path.join(yolo_data_path, \"images\")\n",
    "if not os.path.exists(yolo_images_path):\n",
    "    os.mkdir(yolo_images_path)\n",
    "    \n",
    "# Copy the images to the new directory\n",
    "for image_name in train_df[\"image_path\"].unique():\n",
    "    image_path = os.path.join(data_path, \"images\", image_name)\n",
    "    new_image_path = os.path.join(yolo_images_path, image_name)\n",
    "    os.system(f\"copy {image_path} {new_image_path}\")\n",
    "\n",
    "# Create a new .txt file for each image\n",
    "for image_name in train_df[\"image_path\"].unique():\n",
    "    image_data = train_df[train_df[\"image_path\"] == image_name]\n",
    "    img = cv2.imread(os.path.join(yolo_images_path, image_name))\n",
    "    h, w, _ = img.shape\n",
    "    txt_path = os.path.join(yolo_images_path, f\"{image_name.split('.')[0]}.txt\")\n",
    "    with open(txt_path, \"w\") as f:\n",
    "        for index, row in image_data.iterrows():\n",
    "            class_id = int(row[\"class\"])\n",
    "\n",
    "            xmin = row[\"xmin\"]\n",
    "            ymin = row[\"ymin\"]\n",
    "            xmax = row[\"xmax\"]\n",
    "            ymax = row[\"ymax\"]\n",
    "\n",
    "            width = xmax - xmin\n",
    "            height = ymax - ymin\n",
    "            center_x = (xmin + xmax) / 2\n",
    "            center_y = (ymin + ymax) / 2\n",
    "            \n",
    "            center_x/=w\n",
    "            center_y/=h\n",
    "            width/=w\n",
    "            height/=h\n",
    "\n",
    "            f.write(f\"{class_id} {center_x} {center_y} {width} {height}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import yaml\n",
    "\n",
    "# Path to the dataset\n",
    "dataset_root = r\"dataset\"\n",
    "dataset_path = r\"dataset/dataset\"\n",
    "\n",
    "# List all image and annotation files in the dataset\n",
    "data_files = [f for f in os.listdir(\"dataset/dataset\") if f.endswith(\".jpg\")]\n",
    "\n",
    "# remove .jpg from the file names\n",
    "data_files = [f[:-4] for f in data_files]\n",
    "\n",
    "# Randomly shuffle the list\n",
    "random.shuffle(data_files)\n",
    "\n",
    "# Split the list into two parts\n",
    "split_idx = int(len(data_files) * 0.95)\n",
    "train, val = data_files[:split_idx], data_files[split_idx:]\n",
    "\n",
    "# Create train and val folders\n",
    "train_path = os.path.join(dataset_root, \"train\")\n",
    "val_path = os.path.join(dataset_root, \"val\")\n",
    "os.makedirs(train_path, exist_ok=True)\n",
    "os.makedirs(val_path, exist_ok=True)\n",
    "\n",
    "# Move train and val files\n",
    "for f in train:\n",
    "    os.rename(f\"{dataset_path}/{f}.jpg\", f\"{train_path}/{f}.jpg\")\n",
    "    os.rename(f\"{dataset_path}/{f}.txt\", f\"{train_path}/{f}.txt\")\n",
    "\n",
    "for f in val:\n",
    "    os.rename(f\"{dataset_path}/{f}.jpg\", f\"{val_path}/{f}.jpg\")\n",
    "    os.rename(f\"{dataset_path}/{f}.txt\", f\"{val_path}/{f}.txt\")\n",
    "\n",
    "# Create a dictionary of class labels\n",
    "classes = {\n",
    "    0: 'GRAFFITI',\n",
    "    1: 'FADED_SIGNAGE',\n",
    "    2: 'POTHOLES',\n",
    "    3: 'GARBAGE',\n",
    "    4: 'CONSTRUCTION_ROAD',\n",
    "    5: 'CLUTTER_SIDEWALK',\n",
    "    6: 'BAD_STREETLIGHT',\n",
    "    7: 'BAD_BILLBOARD',\n",
    "    8: 'SAND_ON_ROAD',\n",
    "    9: 'CLUTTER_SIDEWALK',\n",
    "    10: 'UNKEPT_FACADE'\n",
    "}\n",
    "\n",
    "# Create YAML Data Config File\n",
    "with open(os.path.join(dataset_root, \"data.yml\"), 'w') as f:\n",
    "    yaml.dump(\n",
    "        {\n",
    "            'path': dataset_root,\n",
    "            'train': \"train\",\n",
    "            'val': \"val\",\n",
    "            'nc':  len(classes),\n",
    "            'names': classes,\n",
    "        },\n",
    "\n",
    "        f,\n",
    "        default_flow_style=False\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3d8feac1b94e0de212964c5491da5cade1f0d5ec1a2376a199a59bbeec3e987f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
